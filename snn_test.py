# -*- coding: utf-8 -*-
"""SNN-testing-diff-th.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xEyC8JnkrL8AYUGm0hTHA4ewbdhMIsbN
"""

!pip install snntorch

# imports
import snntorch as snn
from snntorch import spikeplot as splt
from snntorch import spikegen

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

import matplotlib.pyplot as plt
import numpy as np
import itertools

# dataloader arguments
batch_size = 128
data_path='/tmp/data/mnist'

dtype = torch.float
device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")

# Define a transform
transform = transforms.Compose([
            transforms.Resize((28, 28)),
            transforms.Grayscale(),
            transforms.ToTensor(),
            transforms.Normalize((0,), (1,))])

mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)
mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)

# Create DataLoaders
train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)
test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)

# Network Architecture
num_inputs = 28*28
num_hidden = 1000
num_outputs = 10

# Temporal Dynamics
num_steps = 25
beta = 0.95
thres = 2.0

# Define Network
class Net(nn.Module):
    def __init__(self, thres):
        super().__init__()

        # Initialize layers
        self.fc1 = nn.Linear(num_inputs, num_hidden)
        self.lif1 = snn.Leaky(beta=beta, threshold=thres)
        self.fc2 = nn.Linear(num_hidden, num_outputs)
        self.lif2 = snn.Leaky(beta=beta, threshold=thres)

    def forward(self, x):

        # Initialize hidden states at t=0
        mem1 = self.lif1.init_leaky()
        mem2 = self.lif2.init_leaky()

        # Record the final layer
        spk2_rec = []
        mem2_rec = []

        for step in range(num_steps):
            cur1 = self.fc1(x)
            spk1, mem1 = self.lif1(cur1, mem1)
            cur2 = self.fc2(spk1)
            spk2, mem2 = self.lif2(cur2, mem2)
            spk2_rec.append(spk2)
            mem2_rec.append(mem2)

        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)

# Load the network onto CUDA if available
net1 = Net(thres=2.0).to(device)
#net = Net(thres=2.0).to(device)

state_dict = torch.load('/content/weight-march31.pth')
net1.load_state_dict(state_dict)

'''# Load the .pth file
state_dict = torch.load('/content/weight-rpp2.pth')

# Print the keys and values
for key, value in state_dict.items():
  print(key, value.shape)

# Modify the weights of the first linear layer by adding 0.1
state_dict["fc1.weight"] += 0.1

# Save the modified state_dict
torch.save(state_dict, "weight_modified.pth")'''

'''state_dict = torch.load('/content/weight-march31.pth')
net1.load_state_dict(state_dict)'''

# Modify the loaded weights to adapt to the new network's structure
with torch.no_grad():
    net.fc1.weight.copy_(net1.fc1.weight)
    net.fc1.bias.copy_(net1.fc1.bias)
    net.fc2.weight.copy_(net1.fc2.weight)
    net.fc2.bias.copy_(net1.fc2.bias)

# torch.save(net.state_dict(), 'weights2.pth')

# state_dict = torch.load('/content/weight-rpp.pth')
# net.load_state_dict(state_dict)

total = 0
correct = 0

# drop_last switched to False to keep all samples
test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)

with torch.no_grad():
  net.eval()
  for data, targets in test_loader:
    data = data.to(device)
    targets = targets.to(device)

    # forward pass
    test_spk, _ = net(data.view(data.size(0), -1))

    # calculate total accuracy
    _, predicted = test_spk.sum(dim=0).max(1)
    total += targets.size(0)
    correct += (predicted == targets).sum().item()

print(f"Total correctly classified test set images: {correct}/{total}")
print(f"Test Set Accuracy: {100 * correct / total:.2f}%")

# drop_last switched to False to keep all samples
test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)

acc_values = []
thres_values = []
for thres in np.arange(0, 5, 0.5):
  total = 0
  correct = 0
  thres_values.append(thres)
  net = Net(thres=float(thres)).to(device)
  with torch.no_grad():
    net.fc1.weight.copy_(net1.fc1.weight)
    net.fc1.bias.copy_(net1.fc1.bias)
    net.fc2.weight.copy_(net1.fc2.weight)
    net.fc2.bias.copy_(net1.fc2.bias)
    net.eval()
    for data, targets in test_loader:
      data = data.to(device)
      targets = targets.to(device)

      # forward pass
      test_spk, _ = net(data.view(data.size(0), -1))

      # calculate total accuracy
      _, predicted = test_spk.sum(dim=0).max(1)
      total += targets.size(0)
      correct += (predicted == targets).sum().item()

  acc = 100 * correct / total
  acc_values.append(acc)
  print(f"Threshold: {float(thres)}")
  print(f"Total correctly classified test set images : {correct}/{total}")
  print(f"Test Set Accuracy: {acc:.2f}%\n")

# Plot Test Accuracy with different Threshold values
fig = plt.figure(facecolor="w", figsize=(10, 5))
plt.plot(thres_values, acc_values)
plt.title("Accuracy Values with different thresholds")
plt.legend(["Test Accuracy"])
plt.xlabel("Threshold")
plt.ylabel("Accuracy (%)")
plt.show()

import pandas as pd

# Assuming you have two lists: x_values and y_values which were used to create the plot
x_values = thres_values
y_values = acc_values

# Create a DataFrame
df = pd.DataFrame({
    'X_Values': x_values,
    'Y_Values': y_values
})

# Save to CSV
df.to_csv('plot_data-mod-2thv.csv', index=False)